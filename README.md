# tec-NN
TEC-1 Neural Network



## def
Neural networks, also known as artificial neural networks (ANNs), are sophisticated computing systems designed to mimic the structure and functionality of biological neural networks found in animal brains. ANNs consist of interconnected units or nodes known as artificial neurons, which aim to replicate the behavior of neurons in the human brain.

When it comes to tasks like handwriting recognition or facial recognition, the human brain excels at making rapid decisions. Similarly, artificial neural networks are engineered to efficiently process and analyze complex patterns and information, allowing them to excel in these recognition tasks as well.

There exist various types of artificial neural networks, each implemented based on specific mathematical operations and a predefined set of parameters that determine the network's output. These parameters play a crucial role in shaping the behavior and performance of the neural network, as they define the connections and strengths of the connections between artificial neurons. By adjusting these parameters during the training process, neural networks can learn to recognize patterns, classify data, or solve complex problems.

Some common types of artificial neural networks include feedforward neural networks, recurrent neural networks, convolutional neural networks, and generative adversarial networks. Feedforward neural networks are the simplest type, where information flows in one direction, from input to output layers. Recurrent neural networks, on the other hand, introduce loops within the network, enabling them to process sequential data or time-dependent information. Convolutional neural networks specialize in handling grid-like data, such as images, by employing convolutional layers that extract features hierarchically. Lastly, generative adversarial networks consist of two neural networks, a generator and a discriminator, that work together to generate realistic synthetic data.

The training process of neural networks involves presenting them with a labeled dataset and iteratively adjusting the parameters to minimize the difference between the network's output and the desired output. This optimization process, often achieved through backpropagation and gradient descent algorithms, allows neural networks to learn from examples and improve their performance over time.

With their ability to model complex relationships and extract meaningful information from large datasets, artificial neural networks have become a vital tool in various fields, including image and speech recognition, natural language processing, autonomous vehicles, and many more. Their versatility and power make them a cornerstone of modern machine learning and artificial intelligence research and applications.


## code and interfacing
Explore a range of code written in MINT to perform any of the NN operations for experimentation.  I will work on 1, 6 and 20, see wiki.



## iterate
- https://github.com/SteveJustin1963/tec-AI
- https://github.com/SteveJustin1963/tec-memR
- https://github.com/SteveJustin1963/tec-Generative-Adversarial-Network
- https://github.com/SteveJustin1963/tec-BOT
- https://github.com/SteveJustin1963/tec-BRAIN
- https://github.com/SteveJustin1963/tec-GA
- 



## Ref
- https://en.wikipedia.org/wiki/Neural_network
- https://www.investopedia.com/terms/n/neuralnetwork.asp#:~:text=A%20neural%20network%20is%20a,organic%20or%20artificial%20in%20nature.
- https://www.ibm.com/cloud/learn/neural-networks
- https://analyticsindiamag.com/6-types-of-artificial-neural-networks-currently-being-used-in-todays-technology/
- https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/#:~:text=Average%20pooling%20involves%20calculating%20the,6%C3%976%20feature%20map.
- https://dzone.com/articles/the-very-basic-introduction-to-feed-forward-neural
- 
