# tec-NN
TEC-1 Neural Network

"neural networks, are computing systems inspired by the biological neural networks that constitute animal brains. An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain."
"In the case of recognizing handwriting or facial recognition, the brain very quickly makes some decisions."
"There are several kinds of artificial neural networks. These types of networks are implemented based on the mathematical operations and a set of parameters required to determine the output."

### 20 neural network types

1. Feedforward neural network, uses perceptron algorithm 
2. Convolutional neural network, uses deep learning algorithm
3. Recurrent neural network, "are the state of the art algorithm for sequential data and are used by Apple's Siri and and Google's voice search. It is the first algorithm that remembers its input, due to an internal memory, which makes it perfectly suited for machine learning problems that involve sequential data."
4. Long short-term memory, "are a type of recurrent neural network capable of learning order dependence in sequence prediction problems. This is a behavior required in complex problem domains like machine translation, speech recognition, and more. LSTMs are a complex area of deep learning."
5. Gated recurrent unit, "are a gating mechanism in recurrent neural networks, use connections through a sequence of nodes to perform machine learning tasks associated with memory and clustering, for instance, in speech recognition."
6. Echo state network, "is a type of reservoir computer that uses a recurrent neural network with a sparsely connected hidden layer (with typically 1% connectivity). The connectivity and weights of hidden neurons are fixed and randomly assigned. The weights of output neurons can be learned so that the network can produce or reproduce specific temporal patterns." see https://github.com/SteveJustin1963/tec-BRAIN
7. Self-organizing map, "is an unsupervised machine learning technique used to produce a low-dimensional representation of a higher dimensional data set while preserving the topological structure of the data."
8. Neural Turing machine, "is a recurrent neural network model of a Turing machine, its a neural network that can learn to read and write from an external memory, just like a Turing machine. This makes it much more powerful than a traditional neural network, which can only learn to recognize patterns that are present in its training data."
9. Deep belief network, "is a generative graphical model, or alternatively a class of deep neural network, composed of multiple layers of latent variables, with connections between the layers but not between units within each layer."
10. Stacked autoencoder, "is a neural network which is an unsupervised learning algorithm which uses back propagation to generate output value which is almost close to the input value. Iis a type of neural network that uses multiple layers to learn to represent data in a more efficient way. The first layer of a stacked autoencoder learns to represent the input data, and each subsequent layer learns to represent the data that was learned by the previous layer. The final layer of a stacked autoencoder is a decoding layer that takes the learned representation and reconstructs the original input data."
11. Generative adversarial network, " are a clever way of training a generative model by framing the problem as a supervised learning problem with two sub-models: the generator model that we train to generate new examples, and the discriminator model that tries to classify examples as either real (from the domain) or fake (generated). The two models are trained together in a zero-sum game, adversarial, until the discriminator model is fooled about half the time, meaning the generator model is generating plausible examples."
12. Siamese network,  A Siamese neural network is a type of neural network that uses two or more identical subnetworks to process information. The subnetworks share weights and biases, and are typically used to compare two input vectors to see if they are similar.. "is an artificial neural network that uses the same weights while working in tandem on two different input vectors to compute comparable output vectors. Often one of the output vectors is precomputed, thus forming a baseline against which the other output vector is compared. This is similar to comparing fingerprints but can be described more technically as a distance function for locality-sensitive hashing."
13. Highway network
14. Dropout
15. Perceptron
16. Multilayer perceptron
17. Radial basis function network
18. Support vector machine
19. Max-pooling
20. Average-pooling


### iterate
- https://github.com/SteveJustin1963/tec-AI
- https://github.com/SteveJustin1963/tec-memR
- https://github.com/SteveJustin1963/tec-Generative-Adversarial-Network
- https://github.com/SteveJustin1963/tec-BOT
- https://github.com/SteveJustin1963/tec-BRAIN
- https://github.com/SteveJustin1963/tec-GA
- 



### Ref
- https://en.wikipedia.org/wiki/Neural_network
- https://www.investopedia.com/terms/n/neuralnetwork.asp#:~:text=A%20neural%20network%20is%20a,organic%20or%20artificial%20in%20nature.
- https://www.ibm.com/cloud/learn/neural-networks
- https://analyticsindiamag.com/6-types-of-artificial-neural-networks-currently-being-used-in-todays-technology/
- 
